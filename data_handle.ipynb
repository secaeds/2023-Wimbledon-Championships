{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d484df39-49db-4897-975c-63148507f047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每场对局的数据已经被提取并保存。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 加载数据集\n",
    "data_path = 'D:/MCM&ICM/addt_matches.xlsx'  # 请替换为实际路径\n",
    "data = pd.read_excel(data_path)\n",
    "unique_matches = data['match_id'].unique()\n",
    "\n",
    "# 输出文件夹路径\n",
    "output_dir = 'D:/MCM&ICM/add_matches/'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# 提取并保存每场对局的数据，分别从两位选手的视角\n",
    "def extract_and_save_match_data(match_id, data, output_dir):\n",
    "    match_data = data[data['match_id'] == match_id]\n",
    "    player1 = match_data.iloc[0]['player1'].replace(' ', '_')\n",
    "    player2 = match_data.iloc[0]['player2'].replace(' ', '_')\n",
    "    match_number = match_id.split('-')[-1]  # Extract the last four digits\n",
    "\n",
    "    output_file_path_p1 = os.path.join(output_dir, f\"{match_number}_{player1}_1.csv\")\n",
    "    output_file_path_p2 = os.path.join(output_dir, f\"{match_number}_{player2}_2.csv\")\n",
    "    \n",
    "    match_data.to_csv(output_file_path_p1, index=False)\n",
    "    match_data.to_csv(output_file_path_p2, index=False)\n",
    "\n",
    "for match_id in unique_matches:\n",
    "    extract_and_save_match_data(match_id, data, output_dir)\n",
    "\n",
    "print(\"每场对局的数据已经被提取并保存。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7419c319-1291-4a37-9454-241d20edf0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有文件已更新。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def add_if_server_column(file_path):\n",
    "    # 读取数据\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # 确定文件代表player1还是player2（通过文件名）\n",
    "    is_player1 = \"_1.csv\" in file_path\n",
    "    is_player2 = \"_2.csv\" in file_path\n",
    "    \n",
    "    # 根据server列和文件名添加if_server列\n",
    "    if is_player1:\n",
    "        data['if_server'] = (data['server'] == 1).astype(int)\n",
    "    elif is_player2:\n",
    "        data['if_server'] = (data['server'] == 2).astype(int)\n",
    "    \n",
    "    # 保存修改后的数据回同一个文件\n",
    "    data.to_csv(file_path, index=False)\n",
    "\n",
    "# 指定包含所有比赛数据的目录\n",
    "directory_path = 'D:/MCM&ICM/add_matches/'  # 请替换为实际的目录路径\n",
    "\n",
    "# 遍历指定目录中的所有文件\n",
    "for filename in os.listdir(directory_path):\n",
    "    file_path = os.path.join(directory_path, filename)\n",
    "    # 检查是否为CSV文件\n",
    "    if file_path.endswith('.csv'):\n",
    "        add_if_server_column(file_path)\n",
    "\n",
    "print(\"所有文件已更新。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec312338-49be-4ed3-bca4-438e9c8231c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有文件已更新，添加了lead_sets列，其中负数表示落后的set数。\n"
     ]
    }
   ],
   "source": [
    "# 领先的set数\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def add_lead_sets(file_path):\n",
    "    # 读取数据\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # 确定是处理player1还是player2的数据\n",
    "    if \"_1.csv\" in file_path:\n",
    "        # 计算player1领先的set数，可以为负数表示落后\n",
    "        data['lead_sets'] = data['p1_sets'] - data['p2_sets']\n",
    "    elif \"_2.csv\" in file_path:\n",
    "        # 计算player2领先的set数，可以为负数表示落后\n",
    "        data['lead_sets'] = data['p2_sets'] - data['p1_sets']\n",
    "    \n",
    "    # 保存修改后的数据回同一个文件\n",
    "    data.to_csv(file_path, index=False)\n",
    "\n",
    "# 指定包含所有比赛数据的目录\n",
    "directory_path = 'D:/MCM&ICM/add_matches/'  # 请替换为实际的目录路径\n",
    "\n",
    "# 遍历指定目录中的所有文件\n",
    "for filename in os.listdir(directory_path):\n",
    "    file_path = os.path.join(directory_path, filename)\n",
    "    # 检查是否为CSV文件\n",
    "    if file_path.endswith('.csv'):\n",
    "        add_lead_sets(file_path)\n",
    "\n",
    "print(\"所有文件已更新，添加了lead_sets列，其中负数表示落后的set数。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2b4c0ed-6b92-4ccc-af43-0f6af417cf3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有文件已更新，添加了lead_games_current_set列，其中负数表示当前set落后的game数。\n"
     ]
    }
   ],
   "source": [
    "# 添加当前set领先的game数\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def add_lead_games_current_set(file_path):\n",
    "    # 读取数据\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # 确定是处理player1还是player2的数据\n",
    "    if \"_1.csv\" in file_path:\n",
    "        # 计算player1在当前set领先的game数，可以为负数表示落后\n",
    "        data['lead_games_current_set'] = data['p1_games'] - data['p2_games']\n",
    "    elif \"_2.csv\" in file_path:\n",
    "        # 计算player2在当前set领先的game数，可以为负数表示落后\n",
    "        data['lead_games_current_set'] = data['p2_games'] - data['p1_games']\n",
    "    \n",
    "    # 保存修改后的数据回同一个文件\n",
    "    data.to_csv(file_path, index=False)\n",
    "\n",
    "# 指定包含所有比赛数据的目录\n",
    "directory_path = 'D:/MCM&ICM/add_matches/'  # 请替换为实际的目录路径\n",
    "\n",
    "# 遍历指定目录中的所有文件\n",
    "for filename in os.listdir(directory_path):\n",
    "    file_path = os.path.join(directory_path, filename)\n",
    "    # 检查是否为CSV文件\n",
    "    if file_path.endswith('.csv'):\n",
    "        add_lead_games_current_set(file_path)\n",
    "\n",
    "print(\"所有文件已更新，添加了lead_games_current_set列，其中负数表示当前set落后的game数。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6088d13d-a80b-4abc-8204-1e2c2fe3cd45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有文件已更新，添加了second_serve_rate列，表示是否为第二次发球。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def add_second_serve_rate(file_path, data):\n",
    "    # 确定是为player1还是player2添加二发率变量\n",
    "    player_suffix = file_path[-5]  # 获取文件名的倒数第五个字符 ('1' 或 '2')\n",
    "    player_server_column = 'server'  # 用于检查谁在发球\n",
    "    serve_no_column = 'serve_no'  # 用于检查是第一次还是第二次发球\n",
    "    \n",
    "    # 添加二发率变量，如果轮到该球员发球，且发球次数为2，则标记为1，否则为0\n",
    "    if player_suffix == '1':\n",
    "        data['second_serve_rate'] = ((data[player_server_column] == 1) & (data[serve_no_column] == 2)).astype(int)\n",
    "    else:\n",
    "        data['second_serve_rate'] = ((data[player_server_column] == 2) & (data[serve_no_column] == 2)).astype(int)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# 指定包含所有比赛数据的目录\n",
    "directory_path = 'D:/MCM&ICM/add_matches/'  # 替换为实际目录路径\n",
    "\n",
    "# 遍历指定目录中的所有文件\n",
    "for filename in os.listdir(directory_path):\n",
    "    file_path = os.path.join(directory_path, filename)\n",
    "    if file_path.endswith('.csv'):\n",
    "        # 读取数据\n",
    "        data = pd.read_csv(file_path)\n",
    "        # 调用函数来添加二发率变量\n",
    "        data = add_second_serve_rate(file_path, data)\n",
    "        # 保存修改后的数据回同一个文件\n",
    "        data.to_csv(file_path, index=False)\n",
    "\n",
    "print(\"所有文件已更新，添加了second_serve_rate列，表示是否为第二次发球。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccf0ccb8-c1a8-4fc9-9302-dcc7539e459f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有文件已更新，添加了break_point_conversion列，表示破发机会掌握情况。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def add_break_point_conversion(file_path, data):\n",
    "    # 确定是为player1还是player2添加破发机会掌握变量\n",
    "    player_suffix = file_path[-5]  # 获取文件名的倒数第五个字符 ('1' 或 '2')\n",
    "    break_pt_won_column = 'p1_break_pt_won' if player_suffix == '1' else 'p2_break_pt_won'\n",
    "    break_pt_column = 'p1_break_pt' if player_suffix == '1' else 'p2_break_pt'\n",
    "    \n",
    "    # 添加破发机会掌握变量\n",
    "    data['break_point_conversion'] = 0  # 初始化为0\n",
    "    # 有破发机会但没有成功破发\n",
    "    data.loc[(data[break_pt_column] > 0) & (data[break_pt_won_column] == 0), 'break_point_conversion'] = -1\n",
    "    # 有破发机会且成功破发\n",
    "    data.loc[data[break_pt_won_column] > 0, 'break_point_conversion'] = 1\n",
    "    \n",
    "    return data\n",
    "\n",
    "# 指定包含所有比赛数据的目录\n",
    "directory_path = 'D:/MCM&ICM/add_matches/'  # 替换为实际目录路径\n",
    "\n",
    "# 遍历指定目录中的所有文件\n",
    "for filename in os.listdir(directory_path):\n",
    "    file_path = os.path.join(directory_path, filename)\n",
    "    if file_path.endswith('.csv'):\n",
    "        # 读取数据\n",
    "        data = pd.read_csv(file_path)\n",
    "        # 调用函数来添加破发机会掌握变量\n",
    "        data = add_break_point_conversion(file_path, data)\n",
    "        # 保存修改后的数据回同一个文件\n",
    "        data.to_csv(file_path, index=False)\n",
    "\n",
    "print(\"所有文件已更新，添加了break_point_conversion列，表示破发机会掌握情况。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "38fd6d31-b90d-43b7-9f60-2f99e11f3bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有文件已更新，添加了serve_depth_aggression列，表示发球深度的侵略性。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def add_serve_depth_aggression(file_path, data):\n",
    "    player_suffix = file_path[-5]  # 获取文件名的倒数第五个字符 ('1' 或 '2')\n",
    "    \n",
    "    # 确保serve_depth_aggression初始化为整数类型\n",
    "    data['serve_depth_aggression'] = 0  # 整数类型初始化\n",
    "    \n",
    "    # 如果是该选手的发球局，serve_depth_aggression等于serve_depth的值\n",
    "    # 先确保serve_depth列的数据类型\n",
    "    data['serve_depth'] = data['serve_depth'].astype(int)\n",
    "    serve_condition = (data['server'] == int(player_suffix))\n",
    "    data.loc[serve_condition, 'serve_depth_aggression'] = data.loc[serve_condition, 'serve_depth']\n",
    "    \n",
    "    return data\n",
    "\n",
    "# 指定包含所有比赛数据的目录\n",
    "directory_path = 'D:/MCM&ICM/matches/'  # 替换为实际目录路径\n",
    "\n",
    "# 遍历指定目录中的所有文件\n",
    "for filename in os.listdir(directory_path):\n",
    "    file_path = os.path.join(directory_path, filename)\n",
    "    if file_path.endswith('.csv'):\n",
    "        # 读取数据\n",
    "        data = pd.read_csv(file_path)\n",
    "        # 调用函数来添加serve_depth_aggression变量\n",
    "        data = add_serve_depth_aggression(file_path, data)\n",
    "        # 保存修改后的数据回同一个文件\n",
    "        data.to_csv(file_path, index=False)\n",
    "\n",
    "print(\"所有文件已更新，添加了serve_depth_aggression列，表示发球深度的侵略性。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "322571a6-c466-4b97-b607-ca5cf2e72169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有文件已处理，每个文件都添加了player列，代表研究的运动员。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def process_file(file_path):\n",
    "    # 从文件名提取运动员名字\n",
    "    player_name = os.path.basename(file_path).replace('.csv', '')\n",
    "    \n",
    "    # 读取CSV数据\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # 创建新的player列，值为运动员的名字\n",
    "    data['player'] = player_name\n",
    "    \n",
    "    # 这里假设你想保留player1和player2的数据，但已标记为关于该运动员的数据\n",
    "    # 如果需要进一步处理以合并或替换player1/player2列，请根据具体需求添加代码\n",
    "    \n",
    "    # 保存修改后的数据回同一个文件\n",
    "    data.to_csv(file_path, index=False)\n",
    "\n",
    "# 指定包含所有比赛数据的目录\n",
    "directory_path = 'D:/MCM&ICM/add_matches/'  # 替换为实际目录路径\n",
    "\n",
    "# 遍历指定目录中的所有文件\n",
    "for filename in os.listdir(directory_path):\n",
    "    file_path = os.path.join(directory_path, filename)\n",
    "    if file_path.endswith('.csv'):\n",
    "        # 处理每个文件\n",
    "        process_file(file_path)\n",
    "\n",
    "print(\"所有文件已处理，每个文件都添加了player列，代表研究的运动员。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55fa5a2b-dbe7-4c4f-93ca-1036df6e291c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有文件已处理，添加了hit_untouchable列，表示是否打了untouchable球。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "def process_file(file_path):\n",
    "    # 使用正则表达式从文件名提取选手编号\n",
    "    match = re.search(r'_(\\d)\\.csv$', os.path.basename(file_path))\n",
    "    if match:\n",
    "        player_number = match.group(1)  # 获取选手编号（1或2）\n",
    "\n",
    "        # 读取CSV数据\n",
    "        data = pd.read_csv(file_path)\n",
    "        \n",
    "        # 根据选手编号设置是否打了untouchable球的变量\n",
    "        if player_number == '1':\n",
    "            data['hit_untouchable'] = data['p1_winner'].apply(lambda x: 1 if x == 1 else 0)\n",
    "        else:\n",
    "            data['hit_untouchable'] = data['p2_winner'].apply(lambda x: 1 if x == 1 else 0)\n",
    "        \n",
    "        # 保存修改后的数据回同一个文件\n",
    "        data.to_csv(file_path, index=False)\n",
    "\n",
    "# 指定包含所有比赛数据的目录\n",
    "directory_path = 'D:/MCM&ICM/add_matches/'  # 替换为实际目录路径\n",
    "\n",
    "# 遍历指定目录中的所有文件\n",
    "for filename in os.listdir(directory_path):\n",
    "    file_path = os.path.join(directory_path, filename)\n",
    "    if file_path.endswith('.csv'):\n",
    "        # 处理每个文件\n",
    "        process_file(file_path)\n",
    "\n",
    "print(\"所有文件已处理，添加了hit_untouchable列，表示是否打了untouchable球。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a4132fe-3b8c-426b-96ee-496c5595ade9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有文件已处理，添加了distance_run列，表示选手的跑动距离。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "def process_file(file_path):\n",
    "    # 使用正则表达式从文件名提取选手编号\n",
    "    match = re.search(r'_(\\d)\\.csv$', os.path.basename(file_path))\n",
    "    if match:\n",
    "        player_number = match.group(1)  # 获取选手编号（1或2）\n",
    "\n",
    "        # 读取CSV数据\n",
    "        data = pd.read_csv(file_path)\n",
    "        \n",
    "        # 根据选手编号设置跑动距离的变量\n",
    "        if player_number == '1':\n",
    "            data['distance_run'] = data['p1_distance_run']\n",
    "        else:\n",
    "            data['distance_run'] = data['p2_distance_run']\n",
    "        \n",
    "        # 保存修改后的数据回同一个文件\n",
    "        data.to_csv(file_path, index=False)\n",
    "\n",
    "# 指定包含所有比赛数据的目录\n",
    "directory_path = 'D:/MCM&ICM/add_matches/'  # 替换为实际目录路径\n",
    "\n",
    "# 遍历指定目录中的所有文件\n",
    "for filename in os.listdir(directory_path):\n",
    "    file_path = os.path.join(directory_path, filename)\n",
    "    if file_path.endswith('.csv'):\n",
    "        # 处理每个文件\n",
    "        process_file(file_path)\n",
    "\n",
    "print(\"所有文件已处理，添加了distance_run列，表示选手的跑动距离。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "93e504ca-3b07-48cc-8fcc-6475fbdaef6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有文件已处理，指定的列已被删除。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 定义要删除的列名列表\n",
    "columns_to_delete = [\n",
    "    \"player1\", \"player2\", \"elapsed_time\", \"set_no\", \"game_no\", \"point_no\",\n",
    "    \"p1_sets\", \"p2_sets\", \"p1_games\", \"p2_games\", \"p1_score\", \"p2_score\",\n",
    "    \"server\", \"serve_no\", \"point_victor\", \"p1_points_won\", \"p2_points_won\", \"game_victor\", \"set_victor\",\n",
    "    \"p1_ace\", \"p2_ace\", \"p1_winner\", \"p2_winner\", \"winner_shot_type\",\n",
    "    \"p1_distance_run\", \"p2_distance_run\", \"serve_width\", \"serve_depth\", \"return_depth\"\n",
    "    # 添加其他指定的列名\n",
    "]\n",
    "\n",
    "# 指定包含所有比赛数据的目录\n",
    "directory_path = 'D:/MCM&ICM/matches/'  # 替换为实际目录路径\n",
    "\n",
    "# 遍历指定目录中的所有文件\n",
    "for filename in os.listdir(directory_path):\n",
    "    file_path = os.path.join(directory_path, filename)\n",
    "    if file_path.endswith('.csv'):\n",
    "        # 读取数据\n",
    "        data = pd.read_csv(file_path)\n",
    "        # 删除指定的列\n",
    "        data.drop(columns=columns_to_delete, errors='ignore', inplace=True)\n",
    "        # 保存修改后的数据回同一个文件\n",
    "        data.to_csv(file_path, index=False)\n",
    "\n",
    "print(\"所有文件已处理，指定的列已被删除。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "78d6e1f7-8595-4adb-9e20-0c961dae7e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有文件已处理，指定的列已被删除。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 更新后的要删除的列名列表\n",
    "columns_to_delete = [\n",
    "\n",
    "    # 新增列\n",
    "    \"p1_double_fault\", \"p2_double_fault\",\n",
    "    \"p1_unf_err\", \"p2_unf_err\",\n",
    "    \"p1_net_pt\", \"p2_net_pt\",\n",
    "    \"p1_net_pt_won\", \"p2_net_pt_won\",\n",
    "    \"p1_break_pt\", \"p2_break_pt\",\n",
    "    \"p1_break_pt_won\", \"p2_break_pt_won\",\n",
    "    \"p1_break_pt_missed\", \"p2_break_pt_missed\"\n",
    "]\n",
    "\n",
    "# 指定包含所有比赛数据的目录\n",
    "directory_path = 'D:/MCM&ICM/matches/'  # 替换为实际目录路径\n",
    "\n",
    "# 遍历指定目录中的所有文件\n",
    "for filename in os.listdir(directory_path):\n",
    "    file_path = os.path.join(directory_path, filename)\n",
    "    if file_path.endswith('.csv'):\n",
    "        # 读取数据\n",
    "        data = pd.read_csv(file_path)\n",
    "        # 删除指定的列\n",
    "        data.drop(columns=columns_to_delete, errors='ignore', inplace=True)\n",
    "        # 保存修改后的数据回同一个文件\n",
    "        data.to_csv(file_path, index=False)\n",
    "\n",
    "print(\"所有文件已处理，指定的列已被删除。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cd7d007-a281-4040-93ed-ef810fa51208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有文件已处理，'player'列已更新并移动到第二列位置。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "def process_file(file_path):\n",
    "    # 读取CSV数据\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # 调整player列的值，去除数字编号和前缀\n",
    "    data['player'] = data['player'].apply(lambda x: re.sub(r'^\\d+_(.+)_\\d$', r'\\1', x).replace('_', ' '))\n",
    "    \n",
    "    # 将player列移动到第二列位置\n",
    "    cols = list(data.columns)\n",
    "    cols.insert(1, cols.pop(cols.index('player')))\n",
    "    data = data[cols]\n",
    "    \n",
    "    # 保存修改后的数据回同一个文件\n",
    "    data.to_csv(file_path, index=False)\n",
    "\n",
    "# 指定包含所有比赛数据的目录\n",
    "directory_path = 'D:/MCM&ICM/add_matches/'  # 替换为实际目录路径\n",
    "\n",
    "# 遍历指定目录中的所有文件\n",
    "for filename in os.listdir(directory_path):\n",
    "    file_path = os.path.join(directory_path, filename)\n",
    "    if file_path.endswith('.csv'):\n",
    "        # 处理每个文件\n",
    "        process_file(file_path)\n",
    "\n",
    "print(\"所有文件已处理，'player'列已更新并移动到第二列位置。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "03c700e1-4803-4f5f-9ae8-31f7b40407bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有CSV文件已成功合并到 'all_matches.csv'。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 指定包含所有CSV文件的目录\n",
    "directory_path = 'D:/MCM&ICM/matches/'  # 替换为实际目录路径\n",
    "\n",
    "# 初始化一个空列表来收集DataFrame\n",
    "dataframes = []\n",
    "\n",
    "# 遍历目录下的所有CSV文件\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        # 读取CSV文件并添加到列表中\n",
    "        df = pd.read_csv(file_path)\n",
    "        dataframes.append(df)\n",
    "\n",
    "# 使用concat函数合并所有DataFrame\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# 保存合并后的DataFrame到一个新的CSV文件\n",
    "combined_df.to_csv('D:/MCM&ICM/all_matches.csv', index=False)\n",
    "\n",
    "print(\"所有CSV文件已成功合并到 'all_matches.csv'。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b016703-e976-4264-a53f-48c63d5db2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有文件已处理，每个文件都添加了scored_point列，表示是否得分。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "def process_file(file_path):\n",
    "    # 使用正则表达式从文件名提取选手编号\n",
    "    match = re.search(r'_(\\d)\\.csv$', os.path.basename(file_path))\n",
    "    if match:\n",
    "        player_number = match.group(1)  # 获取选手编号（1或2）\n",
    "\n",
    "        # 读取CSV数据\n",
    "        data = pd.read_csv(file_path)\n",
    "        \n",
    "        # 添加是否得分的变量\n",
    "        if player_number == '1':\n",
    "            # 如果是player1进行研究\n",
    "            data['scored_point'] = data['point_victor'].apply(lambda x: 1 if x == 1 else 0)\n",
    "        else:\n",
    "            # 如果是player2进行研究\n",
    "            data['scored_point'] = data['point_victor'].apply(lambda x: 1 if x == 2 else 0)\n",
    "        \n",
    "        # 保存修改后的数据回同一个文件\n",
    "        data.to_csv(file_path, index=False)\n",
    "\n",
    "# 指定包含所有比赛数据的目录\n",
    "directory_path = 'D:/MCM&ICM/add_matches/'  # 确保这是您存放CSV文件的实际目录路径\n",
    "\n",
    "# 遍历指定目录中的所有文件\n",
    "for filename in os.listdir(directory_path):\n",
    "    file_path = os.path.join(directory_path, filename)\n",
    "    if file_path.endswith('.csv'):\n",
    "        # 处理每个文件\n",
    "        process_file(file_path)\n",
    "\n",
    "print(\"所有文件已处理，每个文件都添加了scored_point列，表示是否得分。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e23f98a7-09c9-40d5-8327-bc3fef33fce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有文件已处理，每个文件都添加了highlight_moment列，表示高光时刻。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "def process_file(file_path):\n",
    "    # 使用正则表达式从文件名提取选手编号\n",
    "    match = re.search(r'_(\\d)\\.csv$', os.path.basename(file_path))\n",
    "    if match:\n",
    "        player_number = match.group(1)  # 获取选手编号（1或2）\n",
    "\n",
    "        # 读取CSV数据\n",
    "        data = pd.read_csv(file_path)\n",
    "        \n",
    "        # 根据选手编号添加高光时刻的变量\n",
    "        if player_number == '1':\n",
    "            # 如果是player1进行研究\n",
    "            data['highlight'] = ((data['p1_winner'] == 1) | (data['p1_break_pt_won'] == 1)).astype(int)\n",
    "        else:\n",
    "            # 如果是player2进行研究\n",
    "            data['highlight'] = ((data['p2_winner'] == 1) | (data['p2_break_pt_won'] == 1)).astype(int)\n",
    "        \n",
    "        # 保存修改后的数据回同一个文件\n",
    "        data.to_csv(file_path, index=False)\n",
    "\n",
    "# 指定包含所有比赛数据的目录\n",
    "directory_path = 'D:/MCM&ICM/add_matches/'  # 确保这是您存放CSV文件的实际目录路径\n",
    "\n",
    "# 遍历指定目录中的所有文件\n",
    "for filename in os.listdir(directory_path):\n",
    "    file_path = os.path.join(directory_path, filename)\n",
    "    if file_path.endswith('.csv'):\n",
    "        # 处理每个文件\n",
    "        process_file(file_path)\n",
    "\n",
    "print(\"所有文件已处理，每个文件都添加了highlight_moment列，表示高光时刻。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fdf80546-e748-4e34-91da-998875c6846d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有highlight变量列已成功合并并保存到 'D:/MCM&ICM/per_vs_sco.csv'。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 初始化一个空的DataFrame来存储合并后的highlight列\n",
    "combined_highlight = pd.DataFrame()\n",
    "\n",
    "# 指定包含所有比赛数据的目录\n",
    "directory_path = 'D:/matches'\n",
    "\n",
    "# 遍历指定目录中的所有CSV文件\n",
    "for filename in sorted(os.listdir(directory_path)):  # 使用sorted确保文件按顺序被处理\n",
    "    file_path = os.path.join(directory_path, filename)\n",
    "    if file_path.endswith('.csv'):\n",
    "        # 读取当前CSV文件\n",
    "        current_df = pd.read_csv(file_path)\n",
    "        # 确保'highlight'列存在\n",
    "        if 'highlight' in current_df.columns:\n",
    "            # 提取'highlight'列并添加到combined_highlight DataFrame\n",
    "            combined_highlight = pd.concat([combined_highlight, current_df['highlight'].reset_index(drop=True)], axis=1)\n",
    "\n",
    "# 将合并后的highlight列保存到新的CSV文件\n",
    "combined_highlight.to_csv('D:/MCM&ICM/per_vs_sco.csv', index=False)\n",
    "\n",
    "print(\"所有highlight变量列已成功合并并保存到 'D:/MCM&ICM/per_vs_sco.csv'。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5982c952-6f21-46a8-b951-768d26cc5f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 初始化存储highlight值的列表\n",
    "highlight_values = []\n",
    "\n",
    "# 遍历D:/matches目录下的所有CSV文件\n",
    "directory_path = 'D:/matches'\n",
    "for filename in os.listdir(directory_path):\n",
    "    file_path = os.path.join(directory_path, filename)\n",
    "    if file_path.endswith('.csv'):\n",
    "        data = pd.read_csv(file_path)\n",
    "        # 假设我们关注的列名是 'highlight_moment'\n",
    "        highlight_values.extend(data['highlight'].tolist())\n",
    "\n",
    "# 读取目标文件\n",
    "target_file_path = 'D:/MCM&ICM/per_vs_sco.csv'\n",
    "target_data = pd.read_csv(target_file_path)\n",
    "\n",
    "# 将收集到的highlight值作为新列添加\n",
    "target_data['highlight'] = highlight_values\n",
    "\n",
    "# 保存更新后的DataFrame到文件\n",
    "target_data.to_csv(target_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6e57f263-e625-4446-83e2-d10db946c089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有文件已处理，每个文件都添加了minus列，表示选手得分差值。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 遍历D:/matches目录下的所有CSV文件\n",
    "directory_path = 'D:/MCM&ICM/matches全'\n",
    "for filename in os.listdir(directory_path):\n",
    "    file_path = os.path.join(directory_path, filename)\n",
    "    if file_path.endswith('.csv'):\n",
    "        data = pd.read_csv(file_path)\n",
    "        # 假设我们关注的列名是 'highlight_moment'\n",
    "        data['minus']=data['p1_points_won']-data['p2_points_won']\n",
    "        \n",
    "        # 保存修改后的数据回同一个文件\n",
    "        data.to_csv(file_path, index=False)\n",
    "\n",
    "print(\"所有文件已处理，每个文件都添加了minus列，表示选手得分差值。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7dcb4dba-ff5f-4030-9251-9cabc52666b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有CSV文件已成功合并到 'add_matches.csv'。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 指定包含所有CSV文件的目录\n",
    "directory_path = 'D:/MCM&ICM/add_matches/'  # 替换为实际目录路径\n",
    "\n",
    "# 初始化一个空列表来收集DataFrame\n",
    "dataframes = []\n",
    "\n",
    "# 遍历目录下的所有CSV文件\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        # 读取CSV文件并添加到列表中\n",
    "        df = pd.read_csv(file_path)\n",
    "        dataframes.append(df)\n",
    "\n",
    "# 使用concat函数合并所有DataFrame\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# 保存合并后的DataFrame到一个新的CSV文件\n",
    "combined_df.to_csv('D:/MCM&ICM/add_matches.csv', index=False)\n",
    "\n",
    "print(\"所有CSV文件已成功合并到 'add_matches.csv'。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c9029ae3-838b-44c9-a806-4f6e0bb8bb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 加载数据\n",
    "df = pd.read_csv('D:/MCM&ICM/disturbed_matches.csv')  # 请替换为你的文件路径\n",
    "\n",
    "# 定义高斯噪音的标准差（控制噪音的强度）\n",
    "std_dev = 0.1  # 可根据需求调整\n",
    "\n",
    "# 对每个变量添加高斯噪音\n",
    "for col in ['if_server', 'lead_sets', 'lead_games_current_set', 'second_serve_rate', 'break_point_conversion',\n",
    "            'hit_untouchable', 'distance_run', 'rally_count', 'speed_mph', 'serve_width_aggression', 'serve_depth_aggression']:\n",
    "    # 生成高斯噪音\n",
    "    noise = np.random.normal(0, std_dev, len(df))\n",
    "    # 添加噪音到变量\n",
    "    df[col] += noise\n",
    "\n",
    "# 保存带有高斯噪音的数据到原始文件\n",
    "df.to_csv('D:/MCM&ICM/disturbed_matches.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44369378-d5b5-4119-a189-e09a24b4b977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              match_id          player         player1        player2  \\\n",
      "0  2023-wimbledon-1101  Carlos Alcaraz  Carlos Alcaraz  Jeremy Chardy   \n",
      "1  2023-wimbledon-1101  Carlos Alcaraz  Carlos Alcaraz  Jeremy Chardy   \n",
      "2  2023-wimbledon-1101  Carlos Alcaraz  Carlos Alcaraz  Jeremy Chardy   \n",
      "3  2023-wimbledon-1101  Carlos Alcaraz  Carlos Alcaraz  Jeremy Chardy   \n",
      "4  2023-wimbledon-1101  Carlos Alcaraz  Carlos Alcaraz  Jeremy Chardy   \n",
      "\n",
      "  elapsed_time  set_no  game_no  point_no  p1_sets  p2_sets  ...  \\\n",
      "0     00:00:00       1        1         1        0        0  ...   \n",
      "1     00:00:20       1        1         2        0        0  ...   \n",
      "2     00:00:51       1        1         3        0        0  ...   \n",
      "3     00:01:21       1        1         4        0        0  ...   \n",
      "4     00:01:49       1        1         5        0        0  ...   \n",
      "\n",
      "   zscore_lead_sets  zscore_lead_games_current_set zscore_second_serve_rate  \\\n",
      "0               0.0                            0.0                -0.474179   \n",
      "1               0.0                            0.0                -0.474179   \n",
      "2               0.0                            0.0                -0.474179   \n",
      "3               0.0                            0.0                -0.474179   \n",
      "4               0.0                            0.0                -0.474179   \n",
      "\n",
      "  zscore_break_point_conversion  zscore_hit_untouchable  zscore_distance_run  \\\n",
      "0                      0.042045               -0.443384            -0.486633   \n",
      "1                      0.042045                2.255379            -0.365571   \n",
      "2                      0.042045               -0.443384            -0.371597   \n",
      "3                      0.042045               -0.443384            -0.778100   \n",
      "4                     -4.973948               -0.443384             1.531268   \n",
      "\n",
      "   zscore_rally_count  zscore_speed_mph  zscore_serve_width_aggression  \\\n",
      "0           -0.881681          0.803767                      -0.003450   \n",
      "1            0.181147          1.307198                      -0.003450   \n",
      "2            1.598252         -0.922285                      -1.269856   \n",
      "3            0.181147         -0.346934                       1.262956   \n",
      "4            1.243976          0.947604                       1.262956   \n",
      "\n",
      "   zscore_serve_depth_aggression  \n",
      "0                      -0.690279  \n",
      "1                      -0.690279  \n",
      "2                      -0.690279  \n",
      "3                       1.448690  \n",
      "4                       1.448690  \n",
      "\n",
      "[5 rows x 69 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# 载入数据\n",
    "df = pd.read_csv('D:/MCM&ICM/add_matches.csv')  # 请替换为您的文件路径\n",
    "\n",
    "# 列表中包含所有需要标准化的变量名\n",
    "columns_to_normalize = [\n",
    "    'if_server', 'lead_sets', 'lead_games_current_set', 'second_serve_rate',\n",
    "    'break_point_conversion', 'hit_untouchable', 'distance_run', 'rally_count',\n",
    "    'speed_mph', 'serve_width_aggression', 'serve_depth_aggression'\n",
    "]\n",
    "\n",
    "# 对每个变量进行z-score标准化，并创建新的变量列\n",
    "for col in columns_to_normalize:\n",
    "    df[f'zscore_{col}'] = zscore(df[col])\n",
    "\n",
    "# 保存处理后的DataFrame\n",
    "df.to_csv('D:/MCM&ICM/add_matches.csv', index=False)  # 替换为您想保存的文件路径\n",
    "\n",
    "# 显示处理后的DataFrame的前几行以验证\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1e2c7056-338f-4478-b48d-435306509b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              match_id          player         player1        player2  \\\n",
      "0  2023-wimbledon-1101  Carlos Alcaraz  Carlos Alcaraz  Jeremy Chardy   \n",
      "1  2023-wimbledon-1101  Carlos Alcaraz  Carlos Alcaraz  Jeremy Chardy   \n",
      "2  2023-wimbledon-1101  Carlos Alcaraz  Carlos Alcaraz  Jeremy Chardy   \n",
      "3  2023-wimbledon-1101  Carlos Alcaraz  Carlos Alcaraz  Jeremy Chardy   \n",
      "4  2023-wimbledon-1101  Carlos Alcaraz  Carlos Alcaraz  Jeremy Chardy   \n",
      "\n",
      "  elapsed_time  set_no  game_no  point_no  p1_sets  p2_sets  ...  \\\n",
      "0      0:00:00       1        1         1        0        0  ...   \n",
      "1      0:00:20       1        1         2        0        0  ...   \n",
      "2      0:00:51       1        1         3        0        0  ...   \n",
      "3      0:01:21       1        1         4        0        0  ...   \n",
      "4      0:01:49       1        1         5        0        0  ...   \n",
      "\n",
      "   zscore_lead_sets  zscore_lead_games_current_set zscore_second_serve_rate  \\\n",
      "0               0.0                            0.0                -0.474179   \n",
      "1               0.0                            0.0                -0.474179   \n",
      "2               0.0                            0.0                -0.474179   \n",
      "3               0.0                            0.0                -0.474179   \n",
      "4               0.0                            0.0                -0.474179   \n",
      "\n",
      "  zscore_break_point_conversion  zscore_hit_untouchable  zscore_distance_run  \\\n",
      "0                      0.042045               -0.443384            -0.486633   \n",
      "1                      0.042045                2.255379            -0.365571   \n",
      "2                      0.042045               -0.443384            -0.371597   \n",
      "3                      0.042045               -0.443384            -0.778100   \n",
      "4                     -4.973948               -0.443384             1.531268   \n",
      "\n",
      "   zscore_rally_count  zscore_speed_mph  zscore_serve_width_aggression  \\\n",
      "0           -0.881681          0.803767                      -0.003450   \n",
      "1            0.181147          1.307198                      -0.003450   \n",
      "2            1.598252         -0.922285                      -1.269856   \n",
      "3            0.181147         -0.346934                       1.262956   \n",
      "4            1.243976          0.947604                       1.262956   \n",
      "\n",
      "   zscore_serve_depth_aggression  \n",
      "0                      -0.690279  \n",
      "1                      -0.690279  \n",
      "2                      -0.690279  \n",
      "3                       1.448690  \n",
      "4                       1.448690  \n",
      "\n",
      "[5 rows x 70 columns]\n"
     ]
    }
   ],
   "source": [
    "# 加了噪音的变量做相同处理\n",
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# 载入数据\n",
    "df = pd.read_csv('D:/MCM&ICM/disturbed_matches.csv')  # 请替换为您的文件路径\n",
    "\n",
    "# 列表中包含所有需要标准化的变量名\n",
    "columns_to_normalize = [\n",
    "    'if_server', 'lead_sets', 'lead_games_current_set', 'second_serve_rate',\n",
    "    'break_point_conversion', 'hit_untouchable', 'distance_run', 'rally_count',\n",
    "    'speed_mph', 'serve_width_aggression', 'serve_depth_aggression'\n",
    "]\n",
    "\n",
    "# 对每个变量进行z-score标准化，并创建新的变量列\n",
    "for col in columns_to_normalize:\n",
    "    df[f'zscore_{col}'] = zscore(df[col])\n",
    "\n",
    "# 保存处理后的DataFrame\n",
    "df.to_csv('D:/MCM&ICM/disturbed_matches.csv', index=False)  # 替换为您想保存的文件路径\n",
    "\n",
    "# 显示处理后的DataFrame的前几行以验证\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "697fb094-4b16-4ee9-9de7-ac394f660507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('D:/MCM&ICM/disturbed_matches.csv')  # Replace with the actual path to your CSV file\n",
    "\n",
    "# Provided coefficient matrix for factor scores\n",
    "coefficient_matrix = np.array([\n",
    "    [0.023, 0.522, 0.038, -0.008, -0.008],\n",
    "    [0.057, -0.018, 0.576, -0.063, -0.104],\n",
    "    [0.319, 0.006, 0.006, -0.014, -0.025],\n",
    "    [0.100, -0.005, -0.009, 0.820, -0.081],\n",
    "    [-0.046, -0.015, -0.020, 0.501, 0.078],\n",
    "    [0.107, -0.042, -0.497, 0.028, -0.008],\n",
    "    [-0.041, -0.032, -0.035, -0.016, 0.952],\n",
    "    [0.300, 0.004, -0.002, 0.009, -0.032],\n",
    "    [0.323, -0.005, 0.070, -0.002, -0.026],\n",
    "    [0.169, 0.114, 0.366, 0.148, 0.234],\n",
    "    [-0.004, 0.515, 0.033, -0.019, -0.030]\n",
    "])\n",
    "\n",
    "# List of standardized variables columns in the order provided\n",
    "zscore_columns = [\n",
    "    'zscore_rally_count', 'zscore_speed_mph', 'zscore_if_server',\n",
    "    'zscore_lead_sets', 'zscore_lead_games_current_set',\n",
    "    'zscore_second_serve_rate', 'zscore_break_point_conversion',\n",
    "    'zscore_serve_width_aggression', 'zscore_serve_depth_aggression',\n",
    "    'zscore_hit_untouchable', 'zscore_distance_run'\n",
    "]\n",
    "\n",
    "# Initialize an empty DataFrame to store the factor scores\n",
    "factor_scores_df = pd.DataFrame(columns=['FAC1', 'FAC2', 'FAC3', 'FAC4', 'FAC5'])\n",
    "\n",
    "# Perform the matrix multiplication for each factor score\n",
    "for i in range(5):\n",
    "    factor_scores_df[f'FAC{i + 1}'] = df[zscore_columns].dot(coefficient_matrix[:, i])\n",
    "\n",
    "# Concatenate the factor scores DataFrame with the original DataFrame\n",
    "df = pd.concat([df, factor_scores_df], axis=1)\n",
    "\n",
    "# Save the updated DataFrame with the factor scores\n",
    "df.to_csv('D:/MCM&ICM/disturbed_matches.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "69410406-9165-4369-9062-1faa554ba879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              match_id          player         player1        player2  \\\n",
      "0  2023-wimbledon-1101  Carlos Alcaraz  Carlos Alcaraz  Jeremy Chardy   \n",
      "1  2023-wimbledon-1101  Carlos Alcaraz  Carlos Alcaraz  Jeremy Chardy   \n",
      "2  2023-wimbledon-1101  Carlos Alcaraz  Carlos Alcaraz  Jeremy Chardy   \n",
      "3  2023-wimbledon-1101  Carlos Alcaraz  Carlos Alcaraz  Jeremy Chardy   \n",
      "4  2023-wimbledon-1101  Carlos Alcaraz  Carlos Alcaraz  Jeremy Chardy   \n",
      "\n",
      "  elapsed_time  set_no  game_no  point_no  p1_sets  p2_sets  ...  \\\n",
      "0      0:00:00       1        1         1        0        0  ...   \n",
      "1      0:00:20       1        1         2        0        0  ...   \n",
      "2      0:00:51       1        1         3        0        0  ...   \n",
      "3      0:01:21       1        1         4        0        0  ...   \n",
      "4      0:01:49       1        1         5        0        0  ...   \n",
      "\n",
      "   zscore_rally_count  zscore_speed_mph zscore_serve_width_aggression  \\\n",
      "0           -0.881681          0.803767                     -0.003450   \n",
      "1            0.181147          1.307198                     -0.003450   \n",
      "2            1.598252         -0.922285                     -1.269856   \n",
      "3            0.181147         -0.346934                      1.262956   \n",
      "4            1.243976          0.947604                      1.262956   \n",
      "\n",
      "  zscore_serve_depth_aggression      FAC1      FAC2      FAC3      FAC4  \\\n",
      "0                     -0.690279 -0.642906 -0.759859  0.431011 -0.098559   \n",
      "1                     -0.690279 -0.134158  0.155881  1.753118  0.258339   \n",
      "2                     -0.690279 -1.064634  0.619912 -0.462628 -0.023240   \n",
      "3                      1.448690  0.387924 -0.340085 -0.053829 -0.021910   \n",
      "4                      1.448690  0.682576  1.541246  0.983982 -0.075590   \n",
      "\n",
      "       FAC5  Weighted_Score  \n",
      "0 -0.078813       -0.087875  \n",
      "1  0.488206        0.141875  \n",
      "2  0.117931       -0.183864  \n",
      "3 -0.055037        0.046366  \n",
      "4 -5.042678        0.089997  \n",
      "\n",
      "[5 rows x 76 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 载入数据\n",
    "file_path = 'D:/MCM&ICM/disturbed_matches.csv'  # 请替换为您本地的文件路径\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 权重向量\n",
    "# weights = [0.29236331, 0.09062282, 0.21510738, 0.29236331, 0.10954318]\n",
    "# 加噪音后得到的权重向量\n",
    "weights = [0.29068723,0.09299461,0.21613928,0.29273795,0.10744093]\n",
    "\n",
    "# 选取相关的因子得分列\n",
    "factors = df[['FAC1', 'FAC2', 'FAC3', 'FAC4', 'FAC5']]\n",
    "\n",
    "# 加权标准化处理\n",
    "# 先对每个因子进行标准化（这里采用的是最大值标准化）\n",
    "normalized_factors = factors / factors.max()\n",
    "\n",
    "# 应用权重向量进行加权\n",
    "weighted_scores = normalized_factors * weights\n",
    "\n",
    "# 将加权得分加总得到最终得分\n",
    "df['Weighted_Score'] = weighted_scores.sum(axis=1)\n",
    "\n",
    "# 保存加权得分后的数据\n",
    "df.to_csv('D:/MCM&ICM/disturbed_matches.csv', index=False)\n",
    "\n",
    "# 查看结果\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "acece839-7542-471c-98a5-2a4974074051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 假设 df 已经包含了加权得分，并且您已经计算了理想最优解和最劣解\n",
    "# 如果还没有计算，您可以使用 df.max() 和 df.min() 在加权得分的基础上进行计算\n",
    "\n",
    "# 读取加权得分文件\n",
    "df = pd.read_csv('D:/MCM&ICM/disturbed_matches.csv')  # 替换为加权得分文件的路径\n",
    "\n",
    "# 计算理想最优解和最劣解\n",
    "ideal_best = df['Weighted_Score'].max()\n",
    "ideal_worst = df['Weighted_Score'].min()\n",
    "\n",
    "# 计算每个选手与理想最优解和最劣解的距离\n",
    "df['Distance_to_Best'] = np.sqrt((df['Weighted_Score'] - ideal_best) ** 2)\n",
    "df['Distance_to_Worst'] = np.sqrt((df['Weighted_Score'] - ideal_worst) ** 2)\n",
    "\n",
    "# 计算相对接近度\n",
    "df['Relative_Closeness'] = df['Distance_to_Worst'] / (df['Distance_to_Best'] + df['Distance_to_Worst'])\n",
    "\n",
    "# 保存更新后的DataFrame\n",
    "df.to_csv('D:/MCM&ICM/disturbed_matches.csv', index=False)  # 替换为保存路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c30458be-8eca-4be3-a7d3-70f04043c136",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your CSV file (replace 'your_data.csv' with the actual file path)\n",
    "df = pd.read_csv('D:/MCM&ICM/add_matches.csv')\n",
    "\n",
    "# Calculate the mean of the 'Relative_Closeness' column\n",
    "mean_relative_closeness = df['Relative_Closeness'].mean()\n",
    "\n",
    "# Calculate 'momentum1' and 'momentum2' based on conditions\n",
    "df['momentum1'] = df.apply(lambda row: row['Relative_Closeness'] - mean_relative_closeness if row['player'] == row['player1'] else None, axis=1)\n",
    "df['momentum2'] = df.apply(lambda row: row['Relative_Closeness'] - mean_relative_closeness if row['player'] != row['player1'] else None, axis=1)\n",
    "\n",
    "# Save the DataFrame with the new columns\n",
    "df.to_csv('D:/MCM&ICM/add_matches.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ff048498-ff40-4a78-9d33-c6f0c0f22622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub-tables have been saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Load the large CSV file\n",
    "df = pd.read_csv('D:/MCM&ICM/add_matches.csv')  # Replace with the path to your large CSV file\n",
    "\n",
    "# Group the DataFrame by 'match_id' and 'player' and create sub-tables\n",
    "grouped = df.groupby(['match_id', 'player'])\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_path = 'D:/MCM&ICM/additional_matches/'  # Replace with your desired output directory\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Save each sub-table to separate CSV files with names based on 'match_id' and 'player'\n",
    "for (match_id, player), sub_table in grouped:\n",
    "    filename = f'sub_table_{str(match_id)[-4:]}_{player}.csv'\n",
    "    sub_table.to_csv(os.path.join(output_path, filename), index=False)\n",
    "\n",
    "print(\"Sub-tables have been saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c6d95a9a-d488-4739-a889-2de4b52a6ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 指定包含CSV文件的文件夹路径\n",
    "folder_path = 'D:/MCM&ICM/test_matches/'  # 替换成你的文件夹路径\n",
    "\n",
    "# 获取文件夹内所有CSV文件的文件名\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# 遍历每个CSV文件并添加新变量\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(folder_path, csv_file)\n",
    "    \n",
    "    # 读取CSV文件\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # 计算新变量 momentum_minus\n",
    "    df['momentum_minus'] = df['momentum1'] - df['momentum2']\n",
    "    \n",
    "    # 保存更新后的CSV文件\n",
    "    new_file_path = os.path.join(folder_path, csv_file)\n",
    "    df.to_csv(new_file_path, index=False)\n",
    "\n",
    "# 所有CSV文件都已经添加了新变量 momentum_minus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "241ec4e0-da2e-4674-be59-5b8fd2a445f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 指定包含CSV文件的文件夹路径\n",
    "folder_path = 'D:/MCM&ICM/test_matches/'  # 替换成你的文件夹路径\n",
    "\n",
    "# 获取文件夹内所有CSV文件的文件名\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# 遍历每个CSV文件并添加新变量\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(folder_path, csv_file)\n",
    "    \n",
    "    # 读取CSV文件\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # 计算新变量 momentum_minus\n",
    "    df['points_minus'] = df['p1_points_won'] - df['p2_points_won']\n",
    "    \n",
    "    # 保存更新后的CSV文件\n",
    "    new_file_path = os.path.join(folder_path, csv_file)\n",
    "    df.to_csv(new_file_path, index=False)\n",
    "\n",
    "# 所有CSV文件都已经添加了新变量 momentum_minus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c8578841-a06d-4698-b0e8-85cfb0167f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 指定包含CSV文件的文件夹路径\n",
    "folder_path = 'D:/MCM&ICM/additional_matches/'\n",
    "\n",
    "# 获取文件夹内所有CSV文件的文件名\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# 遍历每个CSV文件并移动 highlight 列到最后一列\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(folder_path, csv_file)\n",
    "    \n",
    "    # 读取CSV文件\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # 获取 highlight 列\n",
    "    highlight_col = df.pop('highlight')\n",
    "    \n",
    "    # 将 highlight 列添加到 DataFrame 的最后一列\n",
    "    df['highlight'] = highlight_col\n",
    "    \n",
    "    # 保存更新后的CSV文件\n",
    "    new_file_path = os.path.join(folder_path, csv_file)\n",
    "    df.to_csv(new_file_path, index=False)\n",
    "\n",
    "# 所有CSV文件的 highlight 列都已移动到最后一列\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "07336b5a-60ae-4ed5-a22a-5336eaa136e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 指定包含CSV文件的文件夹路径\n",
    "folder_path = 'D:/MCM&ICM/test_matches/'\n",
    "\n",
    "# 获取文件夹内所有CSV文件的文件名\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# 遍历每个CSV文件并移动 highlight 列到最后一列\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(folder_path, csv_file)\n",
    "    \n",
    "    # 读取CSV文件\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # 获取 highlight 列\n",
    "    highlight_col = df.pop('highlight')\n",
    "    \n",
    "    # 将 highlight 列添加到 DataFrame 的最后一列\n",
    "    df['highlight'] = highlight_col\n",
    "    \n",
    "    # 保存更新后的CSV文件\n",
    "    new_file_path = os.path.join(folder_path, csv_file)\n",
    "    df.to_csv(new_file_path, index=False)\n",
    "\n",
    "# 所有CSV文件的 highlight 列都已移动到最后一列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c50b8baf-8ced-407c-bdfc-57697a2187e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 指定包含CSV文件的文件夹路径\n",
    "folder_path = 'D:/MCM&ICM/test_matches/'\n",
    "\n",
    "# 获取文件夹内所有CSV文件的文件名\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# 遍历每个CSV文件并添加新变量\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(folder_path, csv_file)\n",
    "    \n",
    "    # 读取CSV文件\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # 计算新变量 highlight_minus\n",
    "    df['highlight_minus'] = df['highlight1'] - df['highlight2']\n",
    "    \n",
    "    # 保存更新后的CSV文件\n",
    "    new_file_path = os.path.join(folder_path, csv_file)\n",
    "    df.to_csv(new_file_path, index=False)\n",
    "    \n",
    "    # 检查是否所有 highlight_minus 值都为0\n",
    "    if (df['highlight_minus'] == 0).all():\n",
    "        print(f'error: {csv_file}')\n",
    "\n",
    "# 所有CSV文件都已经添加了新变量 highlight_minus，并进行了检验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9308e91a-853c-4cf7-8bd5-9b5f62089933",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 指定包含CSV文件的文件夹路径\n",
    "folder_path = 'D:/MCM&ICM/test_matches/'\n",
    "\n",
    "# 获取文件夹内所有CSV文件的文件名\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# 遍历每个CSV文件并重命名变量列\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(folder_path, csv_file)\n",
    "    \n",
    "    # 读取CSV文件\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # 重命名变量列\n",
    "    df = df.rename(columns={'FAC1': 'FAC1_1', 'FAC2': 'FAC2_1', 'FAC3': 'FAC3_1', 'FAC4': 'FAC4_1', 'FAC5': 'FAC5_1'})\n",
    "    \n",
    "    # 保存更新后的CSV文件\n",
    "    df.to_csv(file_path, index=False)\n",
    "\n",
    "# 所有CSV文件中的变量列名称已被更新\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f6d13945-4cfa-45be-a2f0-6767471fbd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 指定包含CSV文件的文件夹路径\n",
    "folder_path = 'D:/MCM&ICM/additional_matches/'\n",
    "\n",
    "# 获取文件夹内所有CSV文件的文件名\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# 遍历每个CSV文件并重命名变量列\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(folder_path, csv_file)\n",
    "    \n",
    "    # 读取CSV文件\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # 重命名变量列\n",
    "    df = df.rename(columns={'FAC1': 'FAC1_2', 'FAC2': 'FAC2_2', 'FAC3': 'FAC3_2', 'FAC4': 'FAC4_2', 'FAC5': 'FAC5_2'})\n",
    "    \n",
    "    # 保存更新后的CSV文件\n",
    "    df.to_csv(file_path, index=False)\n",
    "\n",
    "# 所有CSV文件中的变量列名称已被更新\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "89bf19e5-1b32-4af6-91c2-24d309d12195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 指定包含CSV文件的文件夹路径\n",
    "folder_path = 'D:/MCM&ICM/test_matches/'\n",
    "\n",
    "# 获取文件夹内所有CSV文件的文件名\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# 遍历每个CSV文件并重命名变量列\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(folder_path, csv_file)\n",
    "    \n",
    "    # 读取CSV文件\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # 获取所有需要重命名的变量列\n",
    "    columns_to_rename = ['zscore_if_server', 'zscore_lead_sets', 'zscore_lead_games_current_set',\n",
    "                         'zscore_second_serve_rate', 'zscore_break_point_conversion',\n",
    "                         'zscore_hit_untouchable', 'zscore_distance_run', 'zscore_rally_count',\n",
    "                         'zscore_speed_mph', 'zscore_serve_width_aggression', 'zscore_serve_depth_aggression',\n",
    "                         'Relative_Closeness']\n",
    "    \n",
    "    # 重命名变量列\n",
    "    for col in columns_to_rename:\n",
    "        df = df.rename(columns={col: f'{col}_1'})\n",
    "    \n",
    "    # 保存更新后的CSV文件\n",
    "    df.to_csv(file_path, index=False)\n",
    "\n",
    "# 所有CSV文件中的变量列名称已被更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0b081451-ceee-40a6-b17f-6cd9cbe62b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 指定包含CSV文件的文件夹路径\n",
    "folder_path = 'D:/MCM&ICM/additional_matches/'\n",
    "\n",
    "# 获取文件夹内所有CSV文件的文件名\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# 遍历每个CSV文件并重命名变量列\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(folder_path, csv_file)\n",
    "    \n",
    "    # 读取CSV文件\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # 获取所有需要重命名的变量列\n",
    "    columns_to_rename = ['zscore_if_server', 'zscore_lead_sets', 'zscore_lead_games_current_set',\n",
    "                         'zscore_second_serve_rate', 'zscore_break_point_conversion',\n",
    "                         'zscore_hit_untouchable', 'zscore_distance_run', 'zscore_rally_count',\n",
    "                         'zscore_speed_mph', 'zscore_serve_width_aggression', 'zscore_serve_depth_aggression',\n",
    "                         'Relative_Closeness']\n",
    "    \n",
    "    # 重命名变量列\n",
    "    for col in columns_to_rename:\n",
    "        df = df.rename(columns={col: f'{col}_2'})\n",
    "    \n",
    "    # 保存更新后的CSV文件\n",
    "    df.to_csv(file_path, index=False)\n",
    "\n",
    "# 所有CSV文件中的变量列名称已被更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d335b683-30d1-4e25-a5a3-3a575d668935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 指定包含CSV文件的文件夹路径\n",
    "folder_path = 'D:/MCM&ICM/additional_matches/'\n",
    "\n",
    "# 获取文件夹内所有CSV文件的文件名\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# 遍历每个CSV文件并重命名\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(folder_path, csv_file)\n",
    "    \n",
    "    # 解析比赛编号（xxxx）和选手名字（name）\n",
    "    parts = csv_file.split('_')\n",
    "    match_number = parts[2]  # xxxx\n",
    "    player_name = parts[3]  # name\n",
    "    \n",
    "    # 根据比赛编号重命名文件\n",
    "    new_file_name = f\"{'usopen' if match_number in ['1102', '1105', '1107'] else 'wimbledon'}_{match_number}.csv\"\n",
    "    \n",
    "    # 构建新的文件路径\n",
    "    new_file_path = os.path.join(folder_path, new_file_name)\n",
    "    \n",
    "    # 重命名文件\n",
    "    os.rename(file_path, new_file_path)\n",
    "\n",
    "# 所有CSV文件的名字已被更新\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fe14e966-4f7a-42d1-a9f7-8a584e810439",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 指定两个包含CSV文件的文件夹路径\n",
    "folder1_path = 'D:/MCM&ICM/additional_matches/'\n",
    "folder2_path = 'D:/MCM&ICM/test_matches/'\n",
    "output_folder = 'D:/MCM&ICM/exam_matches/'\n",
    "\n",
    "# 获取两个文件夹内所有CSV文件的文件名\n",
    "folder1_files = [f for f in os.listdir(folder1_path) if f.endswith('.csv')]\n",
    "folder2_files = [f for f in os.listdir(folder2_path) if f.endswith('.csv')]\n",
    "\n",
    "# 遍历两个文件夹中的CSV文件并横向合并同名文件\n",
    "for file1 in folder1_files:\n",
    "    for file2 in folder2_files:\n",
    "        if file1 == file2:\n",
    "            # 读取两个文件的数据\n",
    "            df1 = pd.read_csv(os.path.join(folder1_path, file1))\n",
    "            df2 = pd.read_csv(os.path.join(folder2_path, file2))\n",
    "            \n",
    "            # 横向合并两个文件\n",
    "            merged_df = pd.concat([df1, df2], axis=1)\n",
    "            \n",
    "            # 构建新文件的路径\n",
    "            new_file_path = os.path.join(output_folder, file1)\n",
    "            \n",
    "            # 保存合并后的文件\n",
    "            merged_df.to_csv(new_file_path, index=False)\n",
    "\n",
    "# 所有同名文件已被横向合并并保存在指定文件夹中\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3d3c5da6-2535-4c2d-99f1-73bbee2c2f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 指定包含新CSV文件的文件夹路径\n",
    "csv_folder = 'D:/MCM&ICM/exam_matches/'\n",
    "\n",
    "# 获取文件夹内所有CSV文件的文件名\n",
    "csv_files = [f for f in os.listdir(csv_folder) if f.endswith('.csv')]\n",
    "\n",
    "# 遍历所有CSV文件\n",
    "for csv_file in csv_files:\n",
    "    # 读取CSV文件\n",
    "    df = pd.read_csv(os.path.join(csv_folder, csv_file))\n",
    "    \n",
    "    # 检查是否存在player和player2列\n",
    "    if 'player' in df.columns and 'player2' in df.columns:\n",
    "        # 获取player和player2列\n",
    "        player_col = df['player']\n",
    "        player2_col = df['player2']\n",
    "        \n",
    "        # 比较player列和player2列是否相同\n",
    "        if not player_col.equals(player2_col):\n",
    "            print(f\"Error: {csv_file} - 'player' column does not match 'player2' column\")\n",
    "    else:\n",
    "        print(f\"Error: {csv_file} - 'player' or 'player2' column not found\")\n",
    "\n",
    "# 输出不匹配的情况\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "857dc9a6-cf2f-497d-a9e1-d5a78a498271",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 指定包含CSV文件的文件夹路径\n",
    "csv_folder = 'D:/MCM&ICM/exam_matches/'\n",
    "\n",
    "# 获取文件夹内所有CSV文件的文件名\n",
    "csv_files = [f for f in os.listdir(csv_folder) if f.endswith('.csv')]\n",
    "\n",
    "# 遍历所有CSV文件\n",
    "for csv_file in csv_files:\n",
    "    # 读取CSV文件\n",
    "    df = pd.read_csv(os.path.join(csv_folder, csv_file))\n",
    "    \n",
    "    # 检查是否存在FAC1_1和FAC1_2列\n",
    "    if 'FAC1_1' in df.columns and 'FAC1_2' in df.columns:\n",
    "        # 计算FAC1_minus\n",
    "        df['FAC1_minus'] = df['FAC1_1'] - df['FAC1_2']\n",
    "    else:\n",
    "        print(f\"Error: {csv_file} - 'FAC1_1' or 'FAC1_2' column not found\")\n",
    "    \n",
    "    # 检查是否存在FAC2_1和FAC2_2列\n",
    "    if 'FAC2_1' in df.columns and 'FAC2_2' in df.columns:\n",
    "        # 计算FAC2_minus\n",
    "        df['FAC2_minus'] = df['FAC2_1'] - df['FAC2_2']\n",
    "    else:\n",
    "        print(f\"Error: {csv_file} - 'FAC2_1' or 'FAC2_2' column not found\")\n",
    "    \n",
    "    # 检查是否存在FAC3_1和FAC3_2列\n",
    "    if 'FAC3_1' in df.columns and 'FAC3_2' in df.columns:\n",
    "        # 计算FAC3_minus\n",
    "        df['FAC3_minus'] = df['FAC3_1'] - df['FAC3_2']\n",
    "    else:\n",
    "        print(f\"Error: {csv_file} - 'FAC3_1' or 'FAC3_2' column not found\")\n",
    "    \n",
    "    # 检查是否存在FAC4_1和FAC4_2列\n",
    "    if 'FAC4_1' in df.columns and 'FAC4_2' in df.columns:\n",
    "        # 计算FAC4_minus\n",
    "        df['FAC4_minus'] = df['FAC4_1'] - df['FAC4_2']\n",
    "    else:\n",
    "        print(f\"Error: {csv_file} - 'FAC4_1' or 'FAC4_2' column not found\")\n",
    "    \n",
    "    # 检查是否存在FAC5_1和FAC5_2列\n",
    "    if 'FAC5_1' in df.columns and 'FAC5_2' in df.columns:\n",
    "        # 计算FAC5_minus\n",
    "        df['FAC5_minus'] = df['FAC5_1'] - df['FAC5_2']\n",
    "    else:\n",
    "        print(f\"Error: {csv_file} - 'FAC5_1' or 'FAC5_2' column not found\")\n",
    "\n",
    "    # 检查是否存在FAC5_1和FAC5_2列\n",
    "    if 'Relative_Closeness_1' in df.columns and 'Relative_Closeness_2' in df.columns:\n",
    "        # 计算FAC5_minus\n",
    "        df['Relative_Closeness_minus'] = df['Relative_Closeness_1'] - df['Relative_Closeness_2']\n",
    "    else:\n",
    "        print(f\"Error: {csv_file} - 'Relative_Closeness_1' or 'Relative_Closeness_2' column not found\")\n",
    "    \n",
    "    # 保存更新后的CSV文件\n",
    "    df.to_csv(os.path.join(csv_folder, csv_file), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d6500b4c-a6a9-4956-887c-8adfc2e07039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 指定包含CSV文件的文件夹路径\n",
    "csv_folder = 'D:/MCM&ICM/exam_matches/'\n",
    "\n",
    "# 获取文件夹内所有CSV文件的文件名\n",
    "csv_files = [f for f in os.listdir(csv_folder) if f.endswith('.csv')]\n",
    "\n",
    "# 遍历所有CSV文件\n",
    "for csv_file in csv_files:\n",
    "    # 读取CSV文件\n",
    "    df = pd.read_csv(os.path.join(csv_folder, csv_file))\n",
    "    \n",
    "    # 删除两个player变量列\n",
    "    if 'player' in df.columns:\n",
    "        df = df.drop(columns=['player'])\n",
    "    if 'player2' in df.columns:\n",
    "        df = df.drop(columns=['player2'])\n",
    "    \n",
    "    # 将所有后缀为_minus的变量列移动到最前面\n",
    "    minus_columns = [col for col in df.columns if col.endswith('_minus')]\n",
    "    other_columns = [col for col in df.columns if not col.endswith('_minus')]\n",
    "    df = df[minus_columns + other_columns]\n",
    "    \n",
    "    # 保存更新后的CSV文件\n",
    "    df.to_csv(os.path.join(csv_folder, csv_file), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2b1c8d50-9711-40d4-ab0c-18063ebb03b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 指定包含CSV文件的文件夹路径\n",
    "csv_folder = 'D:/MCM&ICM/exam_matches/'\n",
    "\n",
    "# 获取文件夹内所有CSV文件的文件名\n",
    "csv_files = [f for f in os.listdir(csv_folder) if f.endswith('.csv')]\n",
    "\n",
    "# 遍历所有CSV文件\n",
    "for csv_file in csv_files:\n",
    "    # 读取CSV文件\n",
    "    df = pd.read_csv(os.path.join(csv_folder, csv_file))\n",
    "    \n",
    "    # 将match_id移动到第一列\n",
    "    if 'match_id' in df.columns:\n",
    "        df = df[['match_id'] + [col for col in df.columns if col != 'match_id']]\n",
    "    \n",
    "    # 将player1移动到第二列\n",
    "    if 'player1' in df.columns:\n",
    "        df = df[['match_id', 'player1'] + [col for col in df.columns if col not in ['match_id', 'player1']]]\n",
    "    \n",
    "    # 将player2.1改名为player2并移动到第三列\n",
    "    if 'player2.1' in df.columns:\n",
    "        df = df.rename(columns={'player2.1': 'player2'})\n",
    "        df = df[['match_id', 'player1', 'player2'] + [col for col in df.columns if col not in ['match_id', 'player1', 'player2']]]\n",
    "    \n",
    "    # 删除所有带.1后缀的变量列\n",
    "    df = df.drop(columns=[col for col in df.columns if col.endswith('.1')])\n",
    "    \n",
    "    # 保存更新后的CSV文件\n",
    "    df.to_csv(os.path.join(csv_folder, csv_file), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d195d8f-0dfc-4c0f-9663-990798f1fa48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
